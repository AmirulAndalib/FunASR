<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Pretrained Models Released on ModelScope &mdash; FunASR  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Pretrained Models on Huggingface" href="huggingface_models.html" />
    <link rel="prev" title="Inverse Text Normalization (ITN)" href="../modelscope_pipeline/itn_pipeline.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            FunASR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/docker.html">Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../funasr/quick_start.html">Quick Start</a></li>
</ul>
<p class="caption"><span class="caption-text">Academic Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../academic_recipe/asr_recipe.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../academic_recipe/punc_recipe.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../academic_recipe/vad_recipe.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../academic_recipe/sv_recipe.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../academic_recipe/sd_recipe.html">Speaker Diarization</a></li>
</ul>
<p class="caption"><span class="caption-text">ModelScope Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modelscope_pipeline/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../egs_modelscope/asr/TEMPLATE/README.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../egs_modelscope/vad/TEMPLATE/README.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../egs_modelscope/punctuation/TEMPLATE/README.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../egs_modelscope/tp/TEMPLATE/README.html">Timestamp Prediction (FA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modelscope_pipeline/sv_pipeline.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modelscope_pipeline/sd_pipeline.html">Speaker Diarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modelscope_pipeline/itn_pipeline.html">Inverse Text Normalization (ITN)</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Pretrained Models Released on ModelScope</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#model-license">Model License</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-usage">Model Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-zoo">Model Zoo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#speech-recognition">Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#paraformer">Paraformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#uniasr-unify-streaming-and-non-streaming">UniASR [Unify Streaming and Non-streaming]</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conformer">Conformer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#multi-talker-speech-recognition">Multi-talker Speech Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#voice-activity-detection">Voice Activity Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="#punctuation-restoration">Punctuation Restoration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#language-models">Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="#speaker-verification">Speaker Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#speaker-diarization">Speaker Diarization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#timestamp-prediction">Timestamp Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inverse-text-normalization-itn">Inverse Text Normalization (ITN)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="huggingface_models.html">Pretrained Models on Huggingface</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmark and Leaderboard</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/benchmark_pipeline_cer.html">Leaderboard IO</a></li>
</ul>
<p class="caption"><span class="caption-text">Funasr Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/build_task.html">Build custom tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Papers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/papers.html">Papers</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/application.html">Audio Cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/application.html#realtime-speech-recognition">Realtime Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/application.html#audio-chat">Audio Chat</a></li>
</ul>
<p class="caption"><span class="caption-text">FQA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../reference/FQA.html">FQA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">FunASR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Pretrained Models Released on ModelScope</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/model_zoo/modelscope_models.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>(<a class="reference internal" href="modelscope_models_zh.html"><span class="doc">简体中文</span></a>|English)</p>
<div class="section" id="pretrained-models-released-on-modelscope">
<h1>Pretrained Models Released on ModelScope<a class="headerlink" href="#pretrained-models-released-on-modelscope" title="Permalink to this headline"></a></h1>
<div class="section" id="model-license">
<h2>Model License<a class="headerlink" href="#model-license" title="Permalink to this headline"></a></h2>
<p>You are free to use, copy, modify, and share FunASR models under the conditions of this agreement. You should indicate the model source and author information when using, copying, modifying and sharing FunASR models. You should keep the relevant names of models in [FunASR software].. Full model license could see <a class="reference external" href="https://github.com/alibaba-damo-academy/FunASR/blob/main/MODEL_LICENSE">license</a></p>
</div>
<div class="section" id="model-usage">
<h2>Model Usage<a class="headerlink" href="#model-usage" title="Permalink to this headline"></a></h2>
<p>Ref to <a class="reference external" href="https://alibaba-damo-academy.github.io/FunASR/en/modelscope_pipeline/quick_start.html">docs</a></p>
</div>
<div class="section" id="model-zoo">
<h2>Model Zoo<a class="headerlink" href="#model-zoo" title="Permalink to this headline"></a></h2>
<p>Here we provided several pretrained models on different datasets. The details of models and datasets can be found on <a class="reference external" href="https://www.modelscope.cn/models?page=1&amp;tasks=auto-speech-recognition">ModelScope</a>.</p>
<div class="section" id="speech-recognition">
<h3>Speech Recognition<a class="headerlink" href="#speech-recognition" title="Permalink to this headline"></a></h3>
<div class="section" id="paraformer">
<h4>Paraformer<a class="headerlink" href="#paraformer" title="Permalink to this headline"></a></h4>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Offline/Online</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary">Paraformer-large</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary">Paraformer-large-long</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Which would deal with arbitrary length input wav</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-en-16k-common-vocab10020/summary">Paraformer-large-en-long</a></td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">Alibaba Speech Data (50000hours)</td>
<td style="text-align: center;">10020</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Which would deal with arbitrary length input wav</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn/summary">Paraformer-large-Spk</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Supporting speaker diarizatioin for ASR results based on paraformer-large-long</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404/summary">Paraformer-large-contextual</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Which supports the hotword customization based on the incentive enhancement, and improves the recall and precision of hotwords.</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1/summary">Paraformer</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (50000hours)</td>
<td style="text-align: center;">8358</td>
<td style="text-align: center;">68M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8404-online/summary">Paraformer-online</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (50000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">68M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">Which could deal with streaming input</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/summary">Paraformer-large-online</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000hours)</td>
<td style="text-align: center;">8404</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">Which could deal with streaming input</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer-tiny-commandword_asr_nat-zh-cn-16k-vocab544-pytorch/summary">Paraformer-tiny</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">Alibaba Speech Data (200hours)</td>
<td style="text-align: center;">544</td>
<td style="text-align: center;">5.2M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Lightweight Paraformer model which supports Mandarin command words recognition</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer_asr_nat-aishell1-pytorch/summary">Paraformer-aishell</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL (178hours)</td>
<td style="text-align: center;">4234</td>
<td style="text-align: center;">43M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_paraformerbert_asr_nat-zh-cn-16k-aishell1-vocab4234-pytorch/summary">ParaformerBert-aishell</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL (178hours)</td>
<td style="text-align: center;">4234</td>
<td style="text-align: center;">43M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformer_asr_nat-zh-cn-16k-aishell2-vocab5212-pytorch/summary">Paraformer-aishell2</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL-2 (1000hours)</td>
<td style="text-align: center;">5212</td>
<td style="text-align: center;">64M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_paraformerbert_asr_nat-zh-cn-16k-aishell2-vocab5212-pytorch/summary">ParaformerBert-aishell2</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL-2 (1000hours)</td>
<td style="text-align: center;">5212</td>
<td style="text-align: center;">64M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table></div>
<div class="section" id="uniasr-unify-streaming-and-non-streaming">
<h4>UniASR [Unify Streaming and Non-streaming]<a class="headerlink" href="#uniasr-unify-streaming-and-non-streaming" title="Permalink to this headline"></a></h4>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Offline/Online</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-zh-cn-16k-common-vocab8358-tensorflow1-online/summary">UniASR</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000 hours)</td>
<td style="text-align: center;">8358</td>
<td style="text-align: center;">100M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR-large_asr_2pass-zh-cn-16k-common-vocab8358-tensorflow1-offline/summary">UniASR-large</a></td>
<td style="text-align: center;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Speech Data (60000 hours)</td>
<td style="text-align: center;">8358</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-en-16k-common-vocab1080-tensorflow1-online/summary">UniASR English</a></td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">Alibaba Speech Data (10000 hours)</td>
<td style="text-align: center;">1080</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-ru-16k-common-vocab1664-tensorflow1-online/summary">UniASR Russian</a></td>
<td style="text-align: center;">RU</td>
<td style="text-align: center;">Alibaba Speech Data (5000 hours)</td>
<td style="text-align: center;">1664</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-ja-16k-common-vocab93-tensorflow1-online/summary">UniASR Japanese</a></td>
<td style="text-align: center;">JA</td>
<td style="text-align: center;">Alibaba Speech Data (5000 hours)</td>
<td style="text-align: center;">5977</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-ko-16k-common-vocab6400-tensorflow1-online/summary">UniASR Korean</a></td>
<td style="text-align: center;">KO</td>
<td style="text-align: center;">Alibaba Speech Data (2000 hours)</td>
<td style="text-align: center;">6400</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-cantonese-CHS-16k-common-vocab1468-tensorflow1-online/summary">UniASR Cantonese (CHS)</a></td>
<td style="text-align: center;">Cantonese (CHS)</td>
<td style="text-align: center;">Alibaba Speech Data (5000 hours)</td>
<td style="text-align: center;">1468</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-id-16k-common-vocab1067-tensorflow1-online/summary">UniASR Indonesian</a></td>
<td style="text-align: center;">ID</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1067</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-vi-16k-common-vocab1001-pytorch-online/summary">UniASR Vietnamese</a></td>
<td style="text-align: center;">VI</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1001</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-es-16k-common-vocab3445-tensorflow1-online/summary">UniASR Spanish</a></td>
<td style="text-align: center;">ES</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">3445</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-pt-16k-common-vocab1617-tensorflow1-online/summary">UniASR Portuguese</a></td>
<td style="text-align: center;">PT</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1617</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-fr-16k-common-vocab3472-tensorflow1-online/summary">UniASR French</a></td>
<td style="text-align: center;">FR</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">3472</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-de-16k-common-vocab3690-tensorflow1-online/summary">UniASR German</a></td>
<td style="text-align: center;">GE</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">3690</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming online unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-fa-16k-common-vocab1257-pytorch-online/summary">UniASR Persian</a></td>
<td style="text-align: center;">FA</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1257</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-my-16k-common-vocab696-pytorch/summary">UniASR Burmese</a></td>
<td style="text-align: center;">MY</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">696</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-he-16k-common-vocab1085-pytorch/summary">UniASR Hebrew</a></td>
<td style="text-align: center;">HE</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1085</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-ur-16k-common-vocab877-pytorch/summary">UniASR Urdu</a></td>
<td style="text-align: center;">UR</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">877</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_UniASR_asr_2pass-tr-16k-common-vocab1582-pytorch/summary">UniASR Turkish</a></td>
<td style="text-align: center;">TR</td>
<td style="text-align: center;">Alibaba Speech Data (1000 hours)</td>
<td style="text-align: center;">1582</td>
<td style="text-align: center;">95M</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">UniASR streaming offline unifying models</td>
</tr>
</tbody>
</table></div>
<div class="section" id="conformer">
<h4>Conformer<a class="headerlink" href="#conformer" title="Permalink to this headline"></a></h4>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Offline/Online</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_conformer_asr_nat-zh-cn-16k-aishell1-vocab4234-pytorch/summary">Conformer</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL (178hours)</td>
<td style="text-align: center;">4234</td>
<td style="text-align: center;">44M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_conformer_asr_nat-zh-cn-16k-aishell2-vocab5212-pytorch/summary">Conformer</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AISHELL-2 (1000hours)</td>
<td style="text-align: center;">5212</td>
<td style="text-align: center;">44M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_conformer_asr-en-16k-vocab4199-pytorch/summary">Conformer</a></td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">Alibaba Speech Data (10000hours)</td>
<td style="text-align: center;">4199</td>
<td style="text-align: center;">220M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="multi-talker-speech-recognition">
<h3>Multi-talker Speech Recognition<a class="headerlink" href="#multi-talker-speech-recognition" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Offline/Online</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/NPU-ASLP/speech_mfcca_asr-zh-cn-16k-alimeeting-vocab4950/summary">MFCCA</a></td>
<td style="text-align: center;">CN</td>
<td style="text-align: center;">AliMeeting、AISHELL-4、Simudata (917hours)</td>
<td style="text-align: center;">4950</td>
<td style="text-align: center;">45M</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">Duration of input wav &lt;= 20s, channel of input wav &lt;= 8 channel</td>
</tr>
</tbody>
</table></div>
<div class="section" id="voice-activity-detection">
<h3>Voice Activity Detection<a class="headerlink" href="#voice-activity-detection" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Sampling Rate</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/summary">FSMN-VAD</a></td>
<td style="text-align: center;">Alibaba Speech Data (5000hours)</td>
<td style="text-align: center;">0.4M</td>
<td style="text-align: center;">16000</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-8k-common/summary">FSMN-VAD</a></td>
<td style="text-align: center;">Alibaba Speech Data (5000hours)</td>
<td style="text-align: center;">0.4M</td>
<td style="text-align: center;">8000</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table></div>
<div class="section" id="punctuation-restoration">
<h3>Punctuation Restoration<a class="headerlink" href="#punctuation-restoration" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: left;">Language</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: center;">Offline/Online</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/punc_ct-transformer_cn-en-common-vocab471067-large/summary">CT-Transformer-Large</a></td>
<td style="text-align: left;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Text Data(100M)</td>
<td style="text-align: center;">1.1G</td>
<td style="text-align: center;">471067</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">large offline punctuation model</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/summary">CT-Transformer</a></td>
<td style="text-align: left;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Text Data(70M)</td>
<td style="text-align: center;">291M</td>
<td style="text-align: center;">272727</td>
<td style="text-align: center;">Offline</td>
<td style="text-align: left;">offline punctuation model</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727/summary">CT-Transformer-Realtime</a></td>
<td style="text-align: left;">CN &amp; EN</td>
<td style="text-align: center;">Alibaba Text Data(70M)</td>
<td style="text-align: center;">288M</td>
<td style="text-align: center;">272727</td>
<td style="text-align: center;">Online</td>
<td style="text-align: left;">online punctuation model</td>
</tr>
</tbody>
</table></div>
<div class="section" id="language-models">
<h3>Language Models<a class="headerlink" href="#language-models" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Vocab Size</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch/summary">Transformer</a></td>
<td style="text-align: center;">Alibaba Speech Data (?hours)</td>
<td style="text-align: center;">57M</td>
<td style="text-align: center;">8404</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table></div>
<div class="section" id="speaker-verification">
<h3>Speaker Verification<a class="headerlink" href="#speaker-verification" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Number Speaker</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_xvector_sv-zh-cn-cnceleb-16k-spk3465-pytorch/summary">Xvector</a></td>
<td style="text-align: center;">CNCeleb (1,200 hours)</td>
<td style="text-align: center;">17.5M</td>
<td style="text-align: center;">3465</td>
<td style="text-align: left;">Xvector, speaker verification, Chinese</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_xvector_sv-en-us-callhome-8k-spk6135-pytorch/summary">Xvector</a></td>
<td style="text-align: center;">CallHome (60 hours)</td>
<td style="text-align: center;">61M</td>
<td style="text-align: center;">6135</td>
<td style="text-align: left;">Xvector, speaker verification, English</td>
</tr>
</tbody>
</table></div>
<div class="section" id="speaker-diarization">
<h3>Speaker Diarization<a class="headerlink" href="#speaker-diarization" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Training Data</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_diarization_sond-zh-cn-alimeeting-16k-n16k4-pytorch/summary">SOND</a></td>
<td style="text-align: center;">AliMeeting (120 hours)</td>
<td style="text-align: center;">40.5M</td>
<td style="text-align: left;">Speaker diarization, profiles and records, Chinese</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://www.modelscope.cn/models/damo/speech_diarization_sond-en-us-callhome-8k-n16k4-pytorch/summary">SOND</a></td>
<td style="text-align: center;">CallHome (60 hours)</td>
<td style="text-align: center;">12M</td>
<td style="text-align: left;">Speaker diarization, profiles and records, English</td>
</tr>
</tbody>
</table></div>
<div class="section" id="timestamp-prediction">
<h3>Timestamp Prediction<a class="headerlink" href="#timestamp-prediction" title="Permalink to this headline"></a></h3>
<p>|                                                    Model Name                                     |  Language  |    Training Data    | Parameters | Notes |
|:————————————————————————————————–:|:————–:|:——————-:|:———-:|:——|
| <a class="reference external" href="https://modelscope.cn/models/damo/speech_timestamp_prediction-v1-16k-offline/summary">TP-Aligner</a> | CN | Alibaba Speech Data (50000hours) |   37.8M    |    Timestamp prediction, Mandarin, middle size |</p>
</div>
<div class="section" id="inverse-text-normalization-itn">
<h3>Inverse Text Normalization (ITN)<a class="headerlink" href="#inverse-text-normalization-itn" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Language</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-en/summary">English</a></td>
<td style="text-align: center;">EN</td>
<td style="text-align: center;">1.54M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-ru/summary">Russian</a></td>
<td style="text-align: center;">RU</td>
<td style="text-align: center;">17.79M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-ja/summary">Japanese</a></td>
<td style="text-align: center;">JA</td>
<td style="text-align: center;">6.8M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-ko/summary">Korean</a></td>
<td style="text-align: center;">KO</td>
<td style="text-align: center;">1.28M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-id/summary">Indonesian</a></td>
<td style="text-align: center;">ID</td>
<td style="text-align: center;">2.06M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-vi/summary">Vietnamese</a></td>
<td style="text-align: center;">VI</td>
<td style="text-align: center;">0.92M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-tl/summary">Tagalog</a></td>
<td style="text-align: center;">TL</td>
<td style="text-align: center;">0.65M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-es/summary">Spanish</a></td>
<td style="text-align: center;">ES</td>
<td style="text-align: center;">1.32M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-pt/summary">Portuguese</a></td>
<td style="text-align: center;">PT</td>
<td style="text-align: center;">1.28M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-fr/summary">French</a></td>
<td style="text-align: center;">FR</td>
<td style="text-align: center;">4.39M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
<tr>
<td style="text-align: center;"><a href="https://modelscope.cn/models/damo/speech_inverse_text_processing_fun-text-processing-itn-de/summary">German</a></td>
<td style="text-align: center;">GE</td>
<td style="text-align: center;">3.95M</td>
<td style="text-align: left;">ITN, ASR post-processing</td>
</tr>
</tbody>
</table></div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../modelscope_pipeline/itn_pipeline.html" class="btn btn-neutral float-left" title="Inverse Text Normalization (ITN)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="huggingface_models.html" class="btn btn-neutral float-right" title="Pretrained Models on Huggingface" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Speech Lab, Alibaba Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>