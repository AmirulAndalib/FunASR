<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Development Guide (File transcription service) &mdash; FunASR  documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            FunASR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/docker.html">Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start.html">Quick Start</a></li>
</ul>
<p class="caption"><span class="caption-text">Academic Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../academic_recipe/asr_recipe.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../academic_recipe/punc_recipe.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../academic_recipe/vad_recipe.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../academic_recipe/sv_recipe.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../academic_recipe/sd_recipe.html">Speaker Diarization</a></li>
</ul>
<p class="caption"><span class="caption-text">ModelScope Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../modelscope_pipeline/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../egs_modelscope/asr/TEMPLATE/README.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../egs_modelscope/vad/TEMPLATE/README.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../egs_modelscope/punctuation/TEMPLATE/README.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../egs_modelscope/tp/TEMPLATE/README.html">Timestamp Prediction (FA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modelscope_pipeline/sv_pipeline.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modelscope_pipeline/sd_pipeline.html">Speaker Diarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modelscope_pipeline/itn_pipeline.html">Inverse Text Normalization (ITN)</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo/modelscope_models.html">Pretrained Models on ModelScope</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo/huggingface_models.html">Pretrained Models on Huggingface</a></li>
</ul>
<p class="caption"><span class="caption-text">Runtime and Service</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readme.html">FunASR Runtime Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDK_tutorial_online.html">FunASR Realtime Transcribe Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDK_tutorial.html">FunASR Offline File Transcription Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../html5/readme.html">Speech Recognition Service Html5 Client Access Interface</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmark and Leaderboard</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark/benchmark_onnx.html">CPU Benchmark (ONNX-python)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark/benchmark_onnx_cpp.html">CPU Benchmark (ONNX-cpp)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark/benchmark_libtorch.html">CPU Benchmark (Libtorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark/benchmark_pipeline_cer.html">Leaderboard IO</a></li>
</ul>
<p class="caption"><span class="caption-text">Funasr Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/build_task.html">Build custom tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Papers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/papers.html">Papers</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/application.html">Audio Cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/application.html#realtime-speech-recognition">Realtime Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/application.html#audio-chat">Audio Chat</a></li>
</ul>
<p class="caption"><span class="caption-text">FQA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../reference/FQA.html">FQA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">FunASR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Advanced Development Guide (File transcription service)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/funasr/runtime/docs/SDK_advanced_guide_online.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="advanced-development-guide-file-transcription-service">
<h1>Advanced Development Guide (File transcription service)<a class="headerlink" href="#advanced-development-guide-file-transcription-service" title="Permalink to this headline"></a></h1>
<p>FunASR provides a Chinese online transcription service that can be deployed locally or on a cloud server with just one click. The core of the service is the FunASR runtime SDK, which has been open-sourced. FunASR-runtime combines various capabilities such as speech endpoint detection (VAD), offline large-scale speech recognition (ASR) using Paraformer-large, online large-scale speech recognition (ASR) using Paraformer-large, and punctuation detection (PUNC), which have all been open-sourced by the speech laboratory of DAMO Academy on the Modelscope community.
This document serves as a development guide for the FunASR online transcription service. If you wish to quickly experience the online transcription service, please refer to the one-click deployment example for the FunASR online transcription service [Quick Start](#Quick Start)。</p>
<div class="section" id="id1">
<h2>镜像启动<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<p>通过下述命令拉取并启动FunASR软件包的docker镜像：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0
mkdir -p ./funasr-runtime-resources/models
sudo docker run -p <span class="m">10095</span>:10095 -it --privileged<span class="o">=</span><span class="nb">true</span> -v ./funasr-runtime-resources/models:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0
</pre></div>
</div>
<p>如果您没有安装docker，可参考<a class="reference external" href="https://alibaba-damo-academy.github.io/FunASR/en/installation/docker_zh.html">Docker安装</a></p>
</div>
<div class="section" id="id2">
<h2>服务端启动<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h2>
<p>docker启动之后，启动 funasr-wss-server-2pass服务程序：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> FunASR/funasr/runtime
./run_server_2pass.sh <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx <span class="se">\</span>
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  <span class="se">\</span>
  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  <span class="se">\</span>
  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx
</pre></div>
</div>
<p>服务端详细参数介绍可参考服务端参数介绍</p>
</div>
<div class="section" id="id3">
<h2>客户端测试与使用<a class="headerlink" href="#id3" title="Permalink to this headline"></a></h2>
<p>下载客户端测试工具目录samples</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>wget https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/sample/funasr_samples.tar.gz
</pre></div>
</div>
<p>我们以Python语言客户端为例，进行说明，支持音频格式（.wav, .pcm），以及多文件列表wav.scp输入，其他版本客户端请参考文档（点击此处），定制服务部署请参考如何定制服务部署</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3 wss_client_asr.py --host <span class="s2">&quot;127.0.0.1&quot;</span> --port <span class="m">10095</span> --mode 2pass
</pre></div>
</div>
</div>
<div class="section" id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this headline"></a></h2>
<div class="section" id="server-startup">
<h3>Server Startup<a class="headerlink" href="#server-startup" title="Permalink to this headline"></a></h3>
<p>pull and run docker image:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0
mkdir -p ./funasr-runtime-resources/models
sudo docker run -p <span class="m">10095</span>:10095 -it --privileged<span class="o">=</span><span class="nb">true</span> -v ./funasr-runtime-resources/models:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0
</pre></div>
</div>
<p>start funasr-wss-server-2pass：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> FunASR/funasr/runtime
./run_server_2pass.sh <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx <span class="se">\</span>
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  <span class="se">\</span>
  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  <span class="se">\</span>
  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx
</pre></div>
</div>
</div>
<div class="section" id="client-testing-and-usage">
<h3>Client Testing and Usage<a class="headerlink" href="#client-testing-and-usage" title="Permalink to this headline"></a></h3>
<p>After running the above installation instructions, the client testing tool directory samples will be downloaded in the default installation directory /root/funasr-runtime-resources (<a class="reference external" href="https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/sample/funasr_samples.tar.gz">download click</a>).
We take the Python language client as an example to explain that it supports multiple audio format inputs (such as .wav, .pcm, .mp3, etc.), video inputs (.mp4, etc.), and multiple file list wav.scp inputs. For other client versions, please refer to the documentation.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3 funasr_wss_client.py --host <span class="s2">&quot;127.0.0.1&quot;</span> --port <span class="m">10095</span> --mode 2pass --audio_in <span class="s2">&quot;../audio/asr_example.wav&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="installation-of-docker">
<h2>Installation of Docker<a class="headerlink" href="#installation-of-docker" title="Permalink to this headline"></a></h2>
<p>The following steps are for manually installing Docker and Docker images. If your Docker image has already been launched, you can ignore this step.</p>
<div class="section" id="installation-of-docker-environment">
<h3>Installation of Docker environment<a class="headerlink" href="#installation-of-docker-environment" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ubuntu：</span>
curl -fsSL https://test.docker.com -o test-docker.sh 
sudo sh test-docker.sh 
<span class="c1"># Debian：</span>
curl -fsSL https://get.docker.com -o get-docker.sh 
sudo sh get-docker.sh 
<span class="c1"># CentOS：</span>
curl -fsSL https://get.docker.com <span class="p">|</span> bash -s docker --mirror Aliyun 
<span class="c1"># MacOS：</span>
brew install --cask --appdir<span class="o">=</span>/Applications docker
</pre></div>
</div>
<p>More details could ref to <a class="reference external" href="https://alibaba-damo-academy.github.io/FunASR/en/installation/docker.html">docs</a></p>
</div>
<div class="section" id="starting-docker">
<h3>Starting Docker<a class="headerlink" href="#starting-docker" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo systemctl start docker
</pre></div>
</div>
</div>
<div class="section" id="pulling-and-launching-images">
<h3>Pulling and launching images<a class="headerlink" href="#pulling-and-launching-images" title="Permalink to this headline"></a></h3>
<p>Use the following command to pull and launch the Docker image for the FunASR runtime-SDK:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0

sudo docker run -p <span class="m">10095</span>:10095 -it --privileged<span class="o">=</span><span class="nb">true</span> -v /root:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.0
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-p &lt;host port&gt;:&lt;mapped docker port&gt;: In the example, host machine (ECS) port 10095 is mapped to port 10095 in the Docker container. Make sure that port 10095 is open in the ECS security rules.

-v &lt;host path&gt;:&lt;mounted Docker path&gt;: In the example, the host machine path /root is mounted to the Docker path /workspace/models.
</pre></div>
</div>
</div>
</div>
<div class="section" id="starting-the-server">
<h2>Starting the server<a class="headerlink" href="#starting-the-server" title="Permalink to this headline"></a></h2>
<p>Use the flollowing script to start the server ：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> FunASR/funasr/runtime
./run_server_2pass.sh <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx <span class="se">\</span>
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  <span class="se">\</span>
  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  <span class="se">\</span>
  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx
</pre></div>
</div>
<p>More details about the script run_server_2pass.sh:</p>
<p>The FunASR-wss-server-2pass supports downloading models from Modelscope. You can set the model download address (–download-model-dir, default is /workspace/models) and the model ID (–model-dir, –vad-dir, –punc-dir). Here is an example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> /workspace/FunASR/funasr/runtime/websocket/build/bin
./funasr-wss-server-2pass  <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --decoder-thread-num <span class="m">32</span> <span class="se">\</span>
  --io-thread-num  <span class="m">8</span> <span class="se">\</span>
  --port <span class="m">10095</span> <span class="se">\</span>
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--download-model-dir: Model download address, download models from Modelscope by setting the model ID.
--model-dir: Modelscope model ID.
--quantize: True for quantized ASR model, False for non-quantized ASR model. Default is True.
--vad-dir: Modelscope model ID.
--vad-quant: True for quantized VAD model, False for non-quantized VAD model. Default is True.
--punc-dir: Modelscope model ID.
--punc-quant: True for quantized PUNC model, False for non-quantized PUNC model. Default is True.
--port: Port number that the server listens on. Default is 10095.
--decoder-thread-num: Number of inference threads that the server starts. Default is 8.
--io-thread-num: Number of IO threads that the server starts. Default is 1.
--certfile &lt;string&gt;: SSL certificate file. Default is ../../../ssl_key/server.crt.
--keyfile &lt;string&gt;: SSL key file. Default is ../../../ssl_key/server.key.
</pre></div>
</div>
<p>After executing the above command, the real-time speech recognition service will be started. If the model is specified as the model ID in ModelScope, the following model will be automatically downloaded from ModelScope:
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/summary">FSMN-VAD</a>，
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx/summary">Paraformer-lagre-online</a>
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx/summary">Paraformer-lagre-offline</a>
<a class="reference external" href="https://www.modelscope.cn/models/damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx/summary">CT-Transformer-online</a></p>
<div class="section" id="exporting-models-from-finetuned-resources">
<h3>Exporting models from finetuned resources<a class="headerlink" href="#exporting-models-from-finetuned-resources" title="Permalink to this headline"></a></h3>
<p>If you want to deploy a finetuned model, you can follow these steps:
Rename the model you want to deploy after finetuning (for example, 10epoch.pb) to model.pb, and replace the original model.pb in Modelscope with this one. If the path of the replaced model is /path/to/finetune/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch, set the path to model-dir.</p>
</div>
</div>
<div class="section" id="starting-the-client">
<h2>Starting the client<a class="headerlink" href="#starting-the-client" title="Permalink to this headline"></a></h2>
<p>After completing the deployment of FunASR online transcription service on the server, you can test and use the service by following these steps. Currently, FunASR-bin supports multiple ways to start the client. The following are command-line examples based on python-client, c++-client, and custom client Websocket communication protocol:</p>
<div class="section" id="python-client">
<h3>python-client<a class="headerlink" href="#python-client" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python funasr_wss_client.py --host <span class="s2">&quot;127.0.0.1&quot;</span> --port <span class="m">10095</span> --mode 2pass --audio_in <span class="s2">&quot;./data/wav.scp&quot;</span> --send_without_sleep --output_dir <span class="s2">&quot;./results&quot;</span>
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--host: the IP address of the server. It can be set to 127.0.0.1 for local testing.
--port: the port number of the server listener.
--audio_in: the audio input. Input can be a path to a wav file or a wav.scp file (a Kaldi-formatted wav list in which each line includes a wav_id followed by a tab and a wav_path).
--output_dir: the path to the recognition result output.
--ssl: whether to use SSL encryption. The default is to use SSL.
--mode: offline, online, 2pass
</pre></div>
</div>
</div>
<div class="section" id="c-client">
<h3>c++-client<a class="headerlink" href="#c-client" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>. /funasr-wss-client-2pass --server-ip <span class="m">127</span>.0.0.1 --port <span class="m">10095</span> --wav-path test.wav --thread-num <span class="m">1</span> --is-ssl <span class="m">1</span>
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--server-ip: the IP address of the server. It can be set to 127.0.0.1 for local testing.
--port: the port number of the server listener.
--wav-path: the audio input. Input can be a path to a wav file or a wav.scp file (a Kaldi-formatted wav list in which each line includes a wav_id followed by a tab and a wav_path).
--is-ssl: whether to use SSL encryption. The default is to use SSL.
--mode: offline, online, 2pass
--thread-num 1 
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Speech Lab, Alibaba Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>