<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Development Guide (File transcription service) &mdash; FunASR  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            FunASR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation/docker.html">Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../funasr/quick_start.html">Quick Start</a></li>
</ul>
<p class="caption"><span class="caption-text">Academic Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../academic_recipe/asr_recipe.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../academic_recipe/punc_recipe.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../academic_recipe/vad_recipe.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../academic_recipe/sv_recipe.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../academic_recipe/sd_recipe.html">Speaker Diarization</a></li>
</ul>
<p class="caption"><span class="caption-text">ModelScope Egs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modelscope_pipeline/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../egs_modelscope/asr/TEMPLATE/README.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../egs_modelscope/vad/TEMPLATE/README.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../egs_modelscope/punctuation/TEMPLATE/README.html">Punctuation Restoration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../egs_modelscope/tp/TEMPLATE/README.html">Timestamp Prediction (FA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modelscope_pipeline/sv_pipeline.html">Speaker Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modelscope_pipeline/sd_pipeline.html">Speaker Diarization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modelscope_pipeline/itn_pipeline.html">Inverse Text Normalization (ITN)</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Zoo</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo/modelscope_models.html">Pretrained Models Released on ModelScope</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo/huggingface_models.html">Pretrained Models on Huggingface</a></li>
</ul>
<p class="caption"><span class="caption-text">Runtime and Service</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readme.html">FunASR Runtime Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDK_tutorial_online.html">FunASR Realtime Transcribe Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDK_tutorial.html">Highlights</a></li>
<li class="toctree-l1"><a class="reference internal" href="SDK_tutorial.html#funasr-offline-file-transcription-service">FunASR Offline File Transcription Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="../html5/readme.html">Speech Recognition Service Html5 Client Access Interface</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmark and Leaderboard</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark/benchmark_pipeline_cer.html">Leaderboard IO</a></li>
</ul>
<p class="caption"><span class="caption-text">Funasr Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/build_task.html">Build custom tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Papers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/papers.html">Papers</a></li>
</ul>
<p class="caption"><span class="caption-text">Application</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/application.html">Audio Cut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/application.html#realtime-speech-recognition">Realtime Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/application.html#audio-chat">Audio Chat</a></li>
</ul>
<p class="caption"><span class="caption-text">FQA</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/FQA.html">FQA</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">FunASR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Advanced Development Guide (File transcription service)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/runtime/docs/SDK_advanced_guide_offline.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="advanced-development-guide-file-transcription-service">
<h1>Advanced Development Guide (File transcription service)<a class="headerlink" href="#advanced-development-guide-file-transcription-service" title="Permalink to this headline"></a></h1>
<p>(<a class="reference internal" href="SDK_advanced_guide_offline_zh.html"><span class="doc">简体中文</span></a>|English)</p>
<p>FunASR Offline File Transcription Software Package provides a powerful speech-to-text offline file transcription service. With a complete speech recognition pipeline, it combines models for speech endpoint detection, speech recognition, punctuation, etc., allowing for the transcription of long audio and video files, spanning several hours, into punctuated text. It supports simultaneous transcription of hundreds of concurrent requests. The output is text with punctuation, including word-level timestamps, and it supports ITN (Initial Time Normalization) and user-defined hotwords. The server-side integration includes ffmpeg, enabling support for various audio and video formats as input. The software package provides client libraries in multiple programming languages such as HTML, Python, C++, Java, and C#, allowing users to use and further develop the software.</p>
<p>This document serves as a development guide for the FunASR offline file transcription service. If you wish to quickly experience the offline file transcription service, please refer to the one-click deployment example for the FunASR offline file transcription service (<a class="reference internal" href="SDK_tutorial.html"><span class="doc">docs</span></a>).</p>
<img src="images/offline_structure.jpg"  width="900"/><table border="1" class="docutils">
<thead>
<tr>
<th>TIME</th>
<th>INFO</th>
<th>IMAGE VERSION</th>
<th>IMAGE ID</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023.11.08</td>
<td>supporting punc-large model, Ngram model, fst hotwords, server-side loading of hotwords, adaptation to runtime structure changes</td>
<td>funasr-runtime-sdk-cpu-0.3.0</td>
<td>caa64bddbb43</td>
</tr>
<tr>
<td>2023.09.19</td>
<td>supporting ITN model</td>
<td>funasr-runtime-sdk-cpu-0.2.2</td>
<td>2c5286be13e9</td>
</tr>
<tr>
<td>2023.08.22</td>
<td>integrated ffmpeg to support various audio and video inputs, supporting nn-hotword model and timestamp model</td>
<td>funasr-runtime-sdk-cpu-0.2.0</td>
<td>1ad3d19e0707</td>
</tr>
<tr>
<td>2023.07.03</td>
<td>1.0 released</td>
<td>funasr-runtime-sdk-cpu-0.1.0</td>
<td>1ad3d19e0707</td>
</tr>
</tbody>
</table><div class="section" id="quick-start">
<h2>Quick start<a class="headerlink" href="#quick-start" title="Permalink to this headline"></a></h2>
<div class="section" id="docker-install">
<h3>Docker install<a class="headerlink" href="#docker-install" title="Permalink to this headline"></a></h3>
<p>If you have already installed Docker, ignore this step!</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/install_docker.sh<span class="p">;</span>
sudo bash install_docker.sh
</pre></div>
</div>
<p>If you do not have Docker installed, please refer to <a class="reference external" href="https://alibaba-damo-academy.github.io/FunASR/en/installation/docker.html">Docker Installation</a></p>
</div>
<div class="section" id="pulling-and-launching-images">
<h3>Pulling and launching images<a class="headerlink" href="#pulling-and-launching-images" title="Permalink to this headline"></a></h3>
<p>Use the following command to pull and launch the Docker image for the FunASR runtime-SDK:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0

sudo docker run -p <span class="m">10095</span>:10095 -it --privileged<span class="o">=</span><span class="nb">true</span> -v /root:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.3.0
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>-p &lt;host port&gt;:&lt;mapped docker port&gt;: In the example, host machine (ECS) port 10095 is mapped to port 10095 in the Docker container. Make sure that port 10095 is open in the ECS security rules.

-v &lt;host path&gt;:&lt;mounted Docker path&gt;: In the example, the host machine path /root is mounted to the Docker path /workspace/models.
</pre></div>
</div>
</div>
<div class="section" id="starting-the-server">
<h3>Starting the server<a class="headerlink" href="#starting-the-server" title="Permalink to this headline"></a></h3>
<p>Use the flollowing script to start the server ：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>nohup bash run_server.sh <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx <span class="se">\</span>
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx  <span class="se">\</span>
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx <span class="se">\</span>
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst <span class="se">\</span>
  --itn-dir thuduj12/fst_itn_zh <span class="se">\</span>
  --hotword /workspace/models/hotwords.txt &gt; log.out <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">&amp;</span>

<span class="c1"># If you want to close ssl，please add：--certfile 0</span>
<span class="c1"># If you want to deploy the timestamp or nn hotword model, please set --model-dir to the corresponding model:</span>
<span class="c1">#   damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx（timestamp）</span>
<span class="c1">#   damo/speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404-onnx（hotword）</span>
<span class="c1"># If you want to load hotwords on the server side, please configure the hotwords in the host machine file ./funasr-runtime-resources/models/hotwords.txt (docker mapping address: /workspace/models/hotwords.txt):</span>
<span class="c1"># One hotword per line, format (hotword weight): 阿里巴巴 20&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="more-details-about-the-script-run-server-sh">
<h3>More details about the script run_server.sh:<a class="headerlink" href="#more-details-about-the-script-run-server-sh" title="Permalink to this headline"></a></h3>
<p>The funasr-wss-server supports downloading models from Modelscope. You can set the model download address (–download-model-dir, default is /workspace/models) and the model ID (–model-dir, –vad-dir, –punc-dir). Here is an example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> /workspace/FunASR/runtime
nohup bash run_server.sh <span class="se">\</span>
  --download-model-dir /workspace/models <span class="se">\</span>
  --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx <span class="se">\</span>
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx <span class="se">\</span>
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx <span class="se">\</span>
  --itn-dir thuduj12/fst_itn_zh <span class="se">\</span>
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst <span class="se">\</span>
  --decoder-thread-num <span class="m">32</span> <span class="se">\</span>
  --io-thread-num  <span class="m">8</span> <span class="se">\</span>
  --port <span class="m">10095</span> <span class="se">\</span>
  --certfile  ../../../ssl_key/server.crt <span class="se">\</span>
  --keyfile ../../../ssl_key/server.key <span class="se">\</span>
  --hotword ../../hotwords.txt &gt; log.out <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">&amp;</span>
</pre></div>
</div>
<p>Introduction to run_server.sh parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--download-model-dir: Model download address, download models from Modelscope by setting the model ID.
--model-dir: modelscope model ID or local model path.
--quantize: True for quantized ASR model, False for non-quantized ASR model. Default is True.
--vad-dir: modelscope model ID or local model path.
--vad-quant: True for quantized VAD model, False for non-quantized VAD model. Default is True.
--punc-dir: modelscope model ID or local model path.
--punc-quant: True for quantized PUNC model, False for non-quantized PUNC model. Default is True.
--itn-dir modelscope model ID or local model path.
--port: Port number that the server listens on. Default is 10095.
--decoder-thread-num: Number of inference threads that the server starts. Default is 8.
--io-thread-num: Number of IO threads that the server starts. Default is 1.
--certfile &lt;string&gt;: SSL certificate file. Default is ../../../ssl_key/server.crt. If you want to close ssl，set 0
--keyfile &lt;string&gt;: SSL key file. Default is ../../../ssl_key/server.key. 
--hotword: Hotword file path, one line for each hotword(e.g.:阿里巴巴 20), if the client provides hot words, then combined with the hot words provided by the client.
</pre></div>
</div>
</div>
<div class="section" id="shutting-down-the-funasr-service">
<h3>Shutting Down the FunASR Service<a class="headerlink" href="#shutting-down-the-funasr-service" title="Permalink to this headline"></a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># Check the PID of the funasr-wss-server process
ps -x | grep funasr-wss-server
kill -9 PID
</pre></div>
</div>
</div>
<div class="section" id="modifying-models-and-other-parameters">
<h3>Modifying Models and Other Parameters<a class="headerlink" href="#modifying-models-and-other-parameters" title="Permalink to this headline"></a></h3>
<p>To replace the currently used model or other parameters, you need to first shut down the FunASR service, make the necessary modifications to the parameters you want to replace, and then restart the FunASR service. The model should be either an ASR/VAD/PUNC model from ModelScope or a fine-tuned model obtained from ModelScope.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># For example, to replace the ASR model with damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx, use the following parameter setting --model-dir
    --model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx 
# Set the port number using --port
    --port &lt;port number&gt;
# Set the number of inference threads the server will start using --decoder-thread-num
    --decoder-thread-num &lt;decoder thread num&gt;
# Set the number of IO threads the server will start using --io-thread-num
    --io-thread-num &lt;io thread num&gt;
# Disable SSL certificate
    --certfile 0
</pre></div>
</div>
<p>After executing the above command, the real-time speech transcription service will be started. If the model is specified as a ModelScope model id, the following models will be automatically downloaded from ModelScope:
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-onnx/summary">FSMN-VAD</a>,
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx/summary">Paraformer-lagre</a>,
<a class="reference external" href="https://www.modelscope.cn/models/damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx/summary">CT-Transformer</a>,
<a class="reference external" href="https://www.modelscope.cn/models/thuduj12/fst_itn_zh/summary">FST-ITN</a>,
<a class="reference external" href="https://www.modelscope.cn/models/damo/speech_ngram_lm_zh-cn-ai-wesp-fst/summary">Ngram lm</a></p>
<p>If you wish to deploy your fine-tuned model (e.g., 10epoch.pb), you need to manually rename the model to model.pb and replace the original model.pb in ModelScope. Then, specify the path as <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>.</p>
</div>
</div>
<div class="section" id="starting-the-client">
<h2>Starting the client<a class="headerlink" href="#starting-the-client" title="Permalink to this headline"></a></h2>
<p>After completing the deployment of FunASR offline file transcription service on the server, you can test and use the service by following these steps. Currently, FunASR-bin supports multiple ways to start the client. The following are command-line examples based on python-client, c++-client, and custom client Websocket communication protocol:</p>
<div class="section" id="python-client">
<h3>python-client<a class="headerlink" href="#python-client" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python funasr_wss_client.py --host <span class="s2">&quot;127.0.0.1&quot;</span> --port <span class="m">10095</span> --mode offline --audio_in <span class="s2">&quot;./data/wav.scp&quot;</span> --send_without_sleep --output_dir <span class="s2">&quot;./results&quot;</span>
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--host: the IP address of the server. It can be set to 127.0.0.1 for local testing.
--port: the port number of the server listener.
--audio_in: the audio input. Input can be a path to a wav file or a wav.scp file (a Kaldi-formatted wav list in which each line includes a wav_id followed by a tab and a wav_path).
--output_dir: the path to the recognition result output.
--ssl: whether to use SSL encryption. The default is to use SSL.
--mode: offline mode.
--hotword: Hotword file path, one line for each hotword(e.g.:阿里巴巴 20)
--use_itn: whether to use itn, the default value is 1 for enabling and 0 for disabling.
</pre></div>
</div>
</div>
<div class="section" id="c-client">
<h3>c++-client<a class="headerlink" href="#c-client" title="Permalink to this headline"></a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>. /funasr-wss-client --server-ip <span class="m">127</span>.0.0.1 --port <span class="m">10095</span> --wav-path test.wav --thread-num <span class="m">1</span> --is-ssl <span class="m">1</span>
</pre></div>
</div>
<p>Introduction to command parameters:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>--server-ip: the IP address of the server. It can be set to 127.0.0.1 for local testing.
--port: the port number of the server listener.
--wav-path: the audio input. Input can be a path to a wav file or a wav.scp file (a Kaldi-formatted wav list in which each line includes a wav_id followed by a tab and a wav_path).
--is-ssl: whether to use SSL encryption. The default is to use SSL.
--hotword: Hotword file path, one line for each hotword(e.g.:阿里巴巴 20)
--use-itn: whether to use itn, the default value is 1 for enabling and 0 for disabling.
</pre></div>
</div>
</div>
<div class="section" id="custom-client">
<h3>Custom client<a class="headerlink" href="#custom-client" title="Permalink to this headline"></a></h3>
<p>If you want to define your own client, see the <a class="reference internal" href="websocket_protocol.html"><span class="doc">Websocket communication protocol</span></a></p>
</div>
</div>
<div class="section" id="how-to-customize-service-deployment">
<h2>How to customize service deployment<a class="headerlink" href="#how-to-customize-service-deployment" title="Permalink to this headline"></a></h2>
<p>The code for FunASR-runtime is open source. If the server and client cannot fully meet your needs, you can further develop them based on your own requirements:</p>
<div class="section" id="id1">
<h3>C++ client<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>https://github.com/alibaba-damo-academy/FunASR/tree/main/runtime/websocket</p>
</div>
<div class="section" id="id2">
<h3>Python client<a class="headerlink" href="#id2" title="Permalink to this headline"></a></h3>
<p>https://github.com/alibaba-damo-academy/FunASR/tree/main/runtime/python/websocket</p>
</div>
<div class="section" id="c-server">
<h3>C++ server<a class="headerlink" href="#c-server" title="Permalink to this headline"></a></h3>
<div class="section" id="vad">
<h4>VAD<a class="headerlink" href="#vad" title="Permalink to this headline"></a></h4>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// The use of the VAD model consists of two steps: FsmnVadInit and FsmnVadInfer:</span>
<span class="n">FUNASR_HANDLE</span> <span class="n">vad_hanlde</span><span class="o">=</span><span class="n">FsmnVadInit</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">thread_num</span><span class="p">);</span>
<span class="c1">// Where: model_path contains &quot;model-dir&quot; and &quot;quantize&quot;, thread_num is the ONNX thread count;</span>
<span class="n">FUNASR_RESULT</span> <span class="n">result</span><span class="o">=</span><span class="n">FsmnVadInfer</span><span class="p">(</span><span class="n">vad_hanlde</span><span class="p">,</span> <span class="n">wav_file</span><span class="p">.</span><span class="n">c_str</span><span class="p">(),</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">16000</span><span class="p">);</span>
<span class="c1">// Where: vad_hanlde is the return value of FunOfflineInit, wav_file is the path to the audio file, and sampling_rate is the sampling rate (default 16k).</span>
</pre></div>
</div>
<p>See the usage example for details <a class="reference external" href="https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/onnxruntime/bin/funasr-onnx-offline-vad.cpp">docs</a></p>
</div>
<div class="section" id="asr">
<h4>ASR<a class="headerlink" href="#asr" title="Permalink to this headline"></a></h4>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>// The use of the ASR model consists of two steps: FunOfflineInit and FunOfflineInfer:
FUNASR_HANDLE asr_hanlde=FunOfflineInit(model_path, thread_num);
// Where: model_path contains &quot;model-dir&quot; and &quot;quantize&quot;, thread_num is the ONNX thread count;
FUNASR_RESULT result=FunOfflineInfer(asr_hanlde, wav_file.c_str(), RASR_NONE, NULL, 16000);
// Where: asr_hanlde is the return value of FunOfflineInit, wav_file is the path to the audio file, and sampling_rate is the sampling rate (default 16k).
</pre></div>
</div>
<p>See the usage example for details, <a class="reference external" href="https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/onnxruntime/bin/funasr-onnx-offline.cpp">docs</a></p>
</div>
<div class="section" id="punc">
<h4>PUNC<a class="headerlink" href="#punc" title="Permalink to this headline"></a></h4>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>// The use of the PUNC model consists of two steps: CTTransformerInit and CTTransformerInfer:
FUNASR_HANDLE punc_hanlde=CTTransformerInit(model_path, thread_num);
// Where: model_path contains &quot;model-dir&quot; and &quot;quantize&quot;, thread_num is the ONNX thread count;
FUNASR_RESULT result=CTTransformerInfer(punc_hanlde, txt_str.c_str(), RASR_NONE, NULL);
// Where: punc_hanlde is the return value of CTTransformerInit, txt_str is the text
</pre></div>
</div>
<p>See the usage example for details, <a class="reference external" href="https://github.com/alibaba-damo-academy/FunASR/blob/main/runtime/onnxruntime/bin/funasr-onnx-offline-punc.cpp">docs</a></p>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Speech Lab, Alibaba Group.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>